---
title: "Problem Set I Solution"
author: 
  - "Tobias Bodentien"
  - "Philipp Grunenberg"
  - "Alexander Haas"
  - "Osama Warshaga"
date: "`r format(Sys.Date(), '%d-%m-%Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo    = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.height = 4     # Höhe in Inches
)
```

# Task 1

The subsequent descriptive analysis is conducted on the detailed fish market data regarding whiting. First, the required packages and dataset are loaded.

```{r}
## Load packages and dataset
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(lmtest)

detailed_data <- read_tsv("../data/detailed_fish_market_data.txt")
```

## Data preparation

The descriptive analysis will focus on price per pound (*pric*), the total quantity received (*totr*) and sold (*tots*) by a dealer in pounds per day in April and May 1992. Therefore, observations for which these variables are *'NA'* are removed via the 'dplyr' package. The dataset has also been filtered for Whiting, as required for Task 1, and arranged by date.

```{r, echo = TRUE}
# delete those rows that have NA for 
# "price","quan", "totr", "tots" and 
# filter for whiting (no king)
detailed_whiting <- detailed_data %>%
  filter(!is.na(pric),
         !is.na(totr),
         !is.na(tots),
         type == "w") %>%
  arrange(date)

print(paste("Obs:", nrow(detailed_whiting),
            "- Vars:", ncol(detailed_whiting)))
```

The cleaned whiting dataset now comprises 478 observations across 17 variables. 

Inspecting the dataset via *'View(detailed_whiting)'* reveals that there are multiple observations for each day in the period from April to May 1992. Each observation depicts a transaction between a customer and the fish dealer. This is particularly important for understanding the next step.

Of the 478 observations, two do not fit. The total quantity that the dealers sold (*tots*) is equal for all rows (i.e. transactions) of the same dealer at a given day. 

What immediately stands out is that only one dealer is observed on almost all days. For this dealer, multiple transactions are always recorded. Only on two days are two dealers observed, as indicated by multiple distinct observations for *tots*. However, these additional dealers are unrepresentative, as there is only one observation for each of them. The remaining observations all appear to come from a single, larger dealer. These two observations are therefore deleted using 'dplyr'.


```{r, echo=TRUE}

## There seem to be two entries in the dataset, where there are two dealer per day.
# Since this is the case only for two out of all days in April and May: 
# drop those two observations 
detailed_whiting <- detailed_whiting %>%
  # frequency of the same tots value for different days
  group_by(date, dayw, tots) %>%
  mutate(n_same_tots = n()) %>%
  
  # number of distinct tots days
  group_by(date, dayw) %>%
  mutate(n_tots_values = n_distinct(tots)) %>%
  ungroup() %>%
  
  # delete rows for which (there are multiple different tots values 
  #                                   AND 
  #                       for which the tot value only appears once)
  filter(!(n_tots_values > 1 & n_same_tots == 1)) %>%
  
  # delete rows that are not longer needed
  select(-n_same_tots, -n_tots_values)

## two cases, where > 1 dealer is present
tots_inconsistent <- detailed_whiting |>
  group_by(date, dayw) |>
  mutate(
    n_tots = n_distinct(tots)
  ) |>
  filter(n_tots > 1) |>
  arrange(date, dayw, tots, totr)
```

With this step the data cleaning process is finished. 

One part of the descriptive analysis of the Whiting data involves analysing data aggregated at a daily level. For this purpose, a new dataset, *detailed_whiting_daily*, is constructed. 

```{r, echo = TRUE}

# dataset for the daily-level
detailed_whiting_daily <- detailed_whiting %>%
  group_by(date) %>%
  summarise(
    avg_pric = mean(pric),
    totr = first(totr),
    tots = first(tots),
    dayw = first(dayw),
    n_trsact = n(),
    strate = first(tots)/first(totr)
  )


```

For each date (*date*) present in the original dataset, the average price (*avg_pric*), *totr*, *tots*, number of transactions (*n_trsact*) and sell-through rate (*strate*) are computed. For any computation involving *totr* or *tots* the first value of the day can be used. This is possible due to the previous data cleaning step, as described above. The sell-through rate measures the proportion of Whiting offered for sale on a given day that is actually sold. More on that later.

## Descriptive analysis

The analysis is split into three sections: Firstly, an analysis of daily sales; secondly, an analysis of prices; and finally, an analysis based on the hours of the day.

In a code chunk that is not printed in this PDF (*'echo=FALSE'*) the different font sizes and some technical variables for the plots are defined. All plots were created using the 'ggplot2' package.

```{r, echo=FALSE}


## define variables for the plots
# themes for plots
theme_fontsize <- theme(
  plot.title = element_text(size = 13),
  plot.subtitle = element_text(size = 9),
  axis.title = element_text(size = 11),
  axis.text = element_text(size = 10),
  legend.text = element_text(size = 10),
)

theme_fontsize_large <- theme(
  plot.title = element_text(size = 16),
  plot.subtitle = element_text(size = 12),
  axis.title = element_text(size = 14),
  axis.text = element_text(size = 13),
  legend.text = element_text(size = 13),
)


# labels for time series data plots
date_seq <- seq(
  from = as.Date("1992-04-06"),
  to   = as.Date("1992-05-15"),
  by   = "day"
)

# format as "MM-YYYY"
day_labels <- format(date_seq, "%d-%m")

# Named character vector: names are month_ids
day_lookup_vec <- setNames(day_labels, c(seq(406,430, by = 1),seq(501,515, by=1)))

break_vec_x_axis <- c(seq(406,430, by = 7),seq(504,515, by=7))
all_days_x_axis <- c(seq(406,430, by = 1),seq(501,515, by=1))
```


```{r}
####
# summary of the daily datset
####
detailed_whiting_daily %>%
  select(totr, tots, n_trsact) %>%
  summary()

detailed_whiting_daily %>%
  select(totr, tots) %>%
  summarise(across(everything(), sd, na.rm = TRUE))
```

**Insight 1:** The summary statistics for *totr*, *tots* and *n_trsact* at a daily level show that the central tendencies of *tots* and *totr* are quite similar, as expected.  Furthermore, both exhibit a significant degree of variation, with standard deviations of 4,381 and 3,691, respectively.  The number of daily transactions also varies considerably, ranging from very quiet to very busy days (minimum of four and a maximum of 57). Overall, these findings suggest substantial day-to-day volatility in the Whiting business. 

\newpage

### Sales analysis

```{r, echo = FALSE}
####
# barchart average sales by dayw (Day of the Week)
####
plot_average_sales_by_weekday <- detailed_whiting_daily %>%
  group_by(dayw) %>%
  summarise(avg_tots = mean(tots, na.rm = TRUE)) %>%
  ggplot(aes(x = factor(dayw), y = avg_tots)) +
  geom_col(fill = "lightblue", colour = "grey20", width = 0.4) + 
  labs(title = "Average Total Sales by Weekday",
       subtitle = "Whiting sales, April-May 1992",
       y = "Sales (lbs)",
       x = NULL)+
  geom_text(
    aes(label = scales::comma(round(avg_tots, 0))),
    vjust = -0.3,
    size = 3
  ) +
  scale_x_discrete(breaks = 1:5,
                   labels = c("Mon", "Tue", "Wed", "Thu", "Fri")) +
  scale_y_continuous(labels = scales::comma) +
  theme_bw() +
  theme_fontsize_large


####
# time series of tots (total sales)
####
tots_plot_df <- detailed_whiting_daily %>%
  select(date, tots) %>%
  complete(date = 406:515,
           fill = list(tots = 0)) %>%
  arrange(date) %>%
  filter(!between(date, 431, 500)) %>%
  mutate(date_fac = factor(date, levels = date))

plot_daily_sales_over_time <- ggplot(tots_plot_df, aes(x=date_fac, y = tots, group = 1)) + 
  geom_col(width = 0.2,
           colour = "lightblue",
           fill="grey10") +
  labs(title = "Daily Total Sales over Time",
       subtitle = "Whiting sales, April-May 1992",
       y = "Sales (lbs)",
       x = NULL)+ 
  scale_x_discrete(breaks = as.character(all_days_x_axis),
                   labels = function(x) {
                     lab <- rep("", length(x))
                     sel <- x %in% as.character(break_vec_x_axis)
                     lab[sel] <- day_lookup_vec[x[sel]]
                     lab
                   }) +
  theme_bw() +
  theme_fontsize_large

```

```{r ,fig.show = "hold", out.width = "50%"}
plot_average_sales_by_weekday
plot_daily_sales_over_time
```

**Insight 2:** The plot on the left shows the average weekly total sales of whiting by day of the week. Sales are lowest on Wednesdays, increasing towards the end of the week with notably higher average volumes on Thursdays and Fridays. This suggests that demand for whiting is strongest just before the weekend.

The right-hand plot shows the total daily sales over the period April–May 1992. It is immediately clear from this plot that only 19 distinct days are observed throughout this period. As this results in a relatively small number of observations at the level of individual days, a boxplot is not used for the analysis. There is considerable fluctuation in sales from day to day, with several pronounced spikes and some much quieter days. This confirms a high level of volatility in daily whiting sales over the observed period. Another interesting observation is that the market was closed on Monday 20 April 1992. This resulted in unusually high sales the next day compared to other Tuesdays in the sample.

Please note, that the code for all plots of Task 1 can be accessed in the '*.Rmd*' file of our Problem Set 1 solution.

```{r, echo = FALSE}
####
# time series of str (sell trough rate)
####
str_plot_df <- detailed_whiting_daily %>%
  select(date, strate) %>%
  complete(date = 406:515,
           fill = list(strate = 0)) %>%
  arrange(date) %>%
  filter(!between(date, 431, 500)) %>%
  mutate(date_fac = factor(date, levels = date))


plot_daily_str_over_time <- ggplot(str_plot_df, aes(x=date_fac, y = strate, group = 1)) + 
  geom_line(size = 0.5,
            colour = "grey20") +
  geom_point(
    data   = subset(str_plot_df, strate > 0),
    size   = 1,
    colour = "grey10"
  ) +
  geom_abline(intercept = 1, 
              slope = 0, 
              linetype = "dashed",
              size = 0.8,
              colour = "skyblue") + 
  labs(title = "Daily Sell-Through Rate over Time",
       subtitle = "Whiting sales, April-May 1992",
       y = "STR",
       x = NULL)+
  scale_y_sqrt(breaks = c(0, 0.5, 1, 2.5, 5, 10)) + 
  scale_x_discrete(breaks = as.character(all_days_x_axis),
                   labels = function(x) {
                     lab <- rep("", length(x))
                     sel <- x %in% as.character(break_vec_x_axis)
                     lab[sel] <- day_lookup_vec[x[sel]]
                     lab
                   }) +
  theme_bw() +
  theme_fontsize
```

```{r, fig.show = "hold", fig.height= 2.5, out.width = "100%"}
plot_daily_str_over_time
```

**Insight 3:** This line chart shows the daily sell-through rate per day over time. It is calculated as the ratio of *tots* to *totr* (i.e. *tots* divided by *totr*). The dashed line at one indicates full sell-through of the day’s deliveries in Whiting. 

On most trading days, the sell-through rate fluctuates around this value, suggesting that sales and incoming supply are roughly balanced. However, there are a few extreme spikes, especially in mid-April and early May, where the sell-through rate is far above one. These indicate days on which much more was sold than was delivered, meaning existing inventory must have been used up,  as can be seen in the previous days spikes (below one). Overall, the figure indicates highly volatile, yet fairly efficient, inventory usage. This is possible because the Whiting can be frozen and sold over the next few days.

### Price analysis

```{r}
####
# correlation between tots (total daily sales) and avg_pric (average price)
####
cor(detailed_whiting_daily$avg_pric,detailed_whiting_daily$tots)
```

With a correlation of around –0.42, there is a moderate negative linear relationship between average daily prices (*avg_pric*) and total daily sales (*tots*). On days with higher prices, total whiting sales tend to be lower.

```{r, echo = FALSE}
####
# boxplot pric(price) by dayw (Day of the Week)
####
plot_price_distr_by_weekday <- ggplot(detailed_whiting, 
       aes(x=factor(dayw), y=pric)) +
  geom_boxplot(fill = "lightblue",         # dezente Farbe
               colour = "grey20",
               width = 0.6,
               outlier.colour = "firebrick",
               outlier.alpha = 0.7,
               outlier.size = 2) + 
  labs(
    x = NULL,
    y = "Price (per lbs)",
    title = "Price Distribution by Weekday",
    subtitle = "Whiting sales, April-May 1992"
  ) +
  scale_x_discrete(breaks = seq(1,5,by=1),
                   labels = c("Mon", "Tue", "Wed", "Thu", "Fri")) +
  scale_y_continuous(labels = scales::comma) +
  theme_bw() +
  theme_fontsize_large


####
# boxplot pric(price) by qual (Qualitiy of the fish)
####
plot_price_distr_by_quality <- detailed_whiting %>%
  filter(!is.na(qual)) %>%
  ggplot(aes(x=factor(qual), y=pric)) +
  geom_boxplot(fill = "lightblue",
               colour = "grey20",
               width = 0.6,
               outlier.colour = "firebrick",
               outlier.alpha = 0.7,
               outlier.size = 2) + 
  labs(
    x = NULL,
    y = "Price (per lbs)",
    title = "Price Distribution by Whiting Quality",
    subtitle = "Whiting sales, April-May 1992"
  ) +
  scale_y_continuous(labels = scales::comma) +
  theme_bw() +
  theme_fontsize_large
```

```{r, fig.show = "hold", out.width = "50%"}
plot_price_distr_by_weekday
plot_price_distr_by_quality
```

**Insight 4:** The boxplots of the price per pound of whiting for different weekdays (left-hand side) and different qualities of whiting (right-hand side) are both calculated at transaction level (i.e. using *detailed_whiting*). 

Prices tend to be lower and less dispersed at the beginning of the week (Monday–Tuesday), becoming higher and more dispersed on Wednesday and especially Thursday. Friday's prices are usually similar to those in the middle of the week, but there are a few very high outliers. This could indicate occasional 'premium' pricing at the end of the week.

The figure on the right shows an unexpected quality effect: higher-quality grades of whiting achieve higher prices, at least in terms of the median. However, the price of grade three is similar to that of grade one and shows substantially higher variability. The maximum price for grade three is also very high compared to grade one. As expected, grades four and five fetch clearly lower prices. This could indicate that customers do not expect Whiting to be a 'premium' product, and that good quality is sufficient.


### Analysis by time of day

```{r, echo = FALSE}
hourly_detailed_whiting <- detailed_whiting %>%
  mutate(time = round(time/100, digits = 0))

# number of transactions per hour 
plot_transactions_per_hour <- hourly_detailed_whiting %>%
  group_by(time) %>%
  summarise(n_sales = n()) %>%
  filter(!is.na(time)) %>%
  ggplot(aes(x = factor(time), y = n_sales)) +
  geom_col(fill = "lightblue", colour = "grey20", width = 0.4) + 
  labs(title = "Number of Transactions per Hour",
       subtitle = "Whiting sales, April-May 1992",
       y = "Transactions",
       x = NULL)+
  geom_text(
    aes(label = scales::comma(round(n_sales, 0))),
    vjust = -0.3,
    size = 3
  ) +
  scale_y_continuous(labels = scales::comma) +
  theme_bw() +
  theme_fontsize_large
  

# average price across hours
plot_average_price_per_hour <- hourly_detailed_whiting %>%
  group_by(time) %>%
  summarise(avg_pric = mean(pric, na.rm = TRUE)) %>%
  filter(!is.na(time)) %>%
  ggplot(aes(x = factor(time), y = avg_pric)) +
  geom_col(fill = "lightblue", colour = "grey20", width = 0.4) + 
  labs(title = "Average Price per Hour",
       subtitle = "Whiting sales, April-May 1992",
       y = "Price (per lbs)",
       x = NULL)+
  geom_text(
    aes(label = scales::comma(round(avg_pric, 2))),
    vjust = -0.3,
    size = 3
  ) +
  scale_y_continuous(labels = scales::comma) +
  theme_bw() +
  theme_fontsize_large
```

```{r, fig.show = "hold", out.width = "50%"}
plot_transactions_per_hour
plot_average_price_per_hour
```

**Insight 5:** The figures on the number of transactions and average price per hour confirm the typical dynamics of a fish market. The market opens at night and peak activity is observed around 6 a.m., after which the transaction volume declines rapidly. According to the bar plot on the right, prices remain relatively stable during the early morning, but then drop sharply at around 8 a.m., in line with the decline in trading activity.

## Conclusion
Overall, the analyses provide a fairly consistent picture of the Whiting market. Nothing stands out as being different from what would be expected in a non-premium fish market.

# Task 3: Moderated Regression

### 3.1 Hypotheses

In this task, we investigate whether the price sensitivity of individual customers depends on specific contextual characteristics of the transaction. Based on plausibility considerations, the following three hypotheses were developed:

------------------------------------------------------------------------

**Hypothesis 1 (H1): Moderation by Product Quality (`qual`)**

-   **Hypothesis:** The quality of the fish has an influence on the price sensitivity of customers.
-   **Rationale:** We expect that higher quality (`qual`) leads to *lower* price sensitivity. A high-quality product, which might be sold to expensive restaurants with higher margins, justifies a higher price and makes customers less susceptible to price fluctuations.

**Hypothesis 2 (H2): Moderation by Payment Method (`cash`)**

-   **Hypothesis:** The use of cash versus charge (invoice) influences price sensitivity.
-   **Rationale:** Paying with cash may have a higher "emotional value" (or "pain of paying") as the amount paid is immediately visible, rather than just appearing on a bill later. We, therefore, expect that cash transactions lead to *higher* price sensitivity.

**Hypothesis 3 (H3): Moderation by Establishment Type (`estb`)**

-   **Hypothesis:** Price sensitivity depends on the customer's type of establishment.
-   **Rationale:** "Fry shops" (`f`) likely operate on lower margins for their final products and thus have a stronger incentive to watch purchase prices than "Stores" (`s`). We, therefore, expect that "fry shops" will exhibit *higher* price sensitivity.

```{r}
#data loading
detailed_data = read_tsv("../data/detailed_fish_market_data.txt")

#1 data preperation
detailed_data_prep <- detailed_data %>%
  filter(!is.na(pric),
         !is.na(quan),
         type == "w") %>%
  arrange(date) %>%
  
  # 1.1 standardization
  group_by(cusn) %>%
  mutate(Qty_Dev = quan - mean(quan, na.rm = TRUE)) %>% #target variable
  ungroup() %>%
  
  # 1.2 mean centering and dummy creation
  mutate(
    price_c = as.numeric(scale(pric, center = TRUE, scale = FALSE)), #main regressor
    quality_c = as.numeric(scale(qual, center = TRUE, scale = FALSE)), # Moderator 1
    cash_dummy = if_else(cash == 'c', 1, 0), # Moderator 2
    estb = as.factor(estb), # Moderator 3
  ) 
```

This is the first cleaning step.

-   We remove any rows where either price (`pric`) or quantity (`quan`) are missing. We cannot model a price-demand relationship without a price or a quantity, so these rows are unusable for our model.
-   We filter the dataset to only include "Whiting". This ensures our analysis is focused on a single product, as combining different fish types would introduce confounding variables.
-   We sort the data ascending by date. While not strictly required for this regression, it's good practice to organize time-series data chronologically, which can help in identifying patterns or debugging later.
-   Next we standardize the consume by customer. This is a crucial step as each customer usually buys different amounts of fish. Therefore we take the mean for every customer and model the amount consumed by the difference to the mean for this customer.
-   Finally we create the main Regressor and the 3 Regressors for the hypothesis.
    -   We mean center `pric` (price) . This makes the coefficients in our moderated regression models much easier to interpret. Specifically, the main effect of price will now represent the price sensitivity at the *average* level of the moderator.
    -   We likewise mean-center our first moderator, `qual` (quality).
    -   We convert the categorical `cash` variable into a numeric **dummy variable** for our second hypothesis. The model can interpret "1" (for cash) and "0" (for non-cash), but it cannot interpret the original 'c' and '0' letters.
    -   We convert the establishment type (`estb`) variable into a **factor**. This tells R that `estb` is a categorical variable. When we include it in the `lm()` function, R will automatically create the necessary dummy variables for each establishment type, allowing us to test our third hypothesis.

```{r}
# additional steps for establishment
detailed_data_prep %>% group_by(estb) %>% count()

detailed_data_perep_estb = detailed_data_prep %>%
  filter(estb %in% c("s", "f", "sf"))
```

This code block performs a crucial diagnostic check and a subsequent filtering action specifically to prepare for testing Hypothesis 3 (moderation by establishment type).

-   Before using a categorical variable as a moderator, we must check its distribution. The output of this count reveals that while some categories like 's' (store) and 'f' (fry shop) have many observations, other categories have very few (e.g., only 1, 2, or 3).
-    Attempting to run a regression or moderation analysis on a categorical level with only 1 or 2 observations is statistically unreliable; the model cannot produce a stable estimate for such a small group. It can lead to model errors or highly misleading results. By filtering down to the well-represented groups, we ensure that our analysis for Hypothesis 3 is robust and that the results are meaningful. This new dataset will be used *only* for the H3 analysis.

```{r}
#2.1 Moderated Model 1
quality_model = lm(Qty_Dev ~ price_c + quality_c, data = detailed_data_prep)
quality_model_moderation = lm(Qty_Dev ~ price_c*quality_c, data = detailed_data_prep)

summary(quality_model)
summary(quality_model_moderation)
```

The results indicate that in both the basic and the moderated models, the estimated parameters are not statistically significant. The model's explanatory power is extremely low, with an $R^2$ below 1%. Consequently, we fail to reject the null hypothesis; there is no statistical evidence in this dataset that price, quality, or their interaction influences the quantity consumed.

```{r}
#Testing if Moderator 1 is significant
anova(quality_model, quality_model_moderation)
lrtest(quality_model, quality_model_moderation)
```

Neither the ANOVA (F-test for nested models) nor the Likelihood Ratio Test (LRT) indicates a significant difference between the models ($p > 0.05$). This confirms that adding the interaction term does not improve model fit, meaning we find no support for the hypothesis that quality moderates price sensitivity (H1).

```{r}
#2.2 Moderated Model 2
cash_model = lm(Qty_Dev ~ price_c+cash_dummy, data=detailed_data_prep)
cash_model_moderation = lm(Qty_Dev ~ price_c*cash_dummy, data=detailed_data_prep)
summary(cash_model)
summary(cash_model_moderation)
```

Similar to the previous analysis, the parameters in both the main effects and interaction models are statistically insignificant. The adjusted $R^2$ remains negligible (\< 1%). We cannot reject the null hypothesis that the payment method (cash vs. credit) has no impact on consumption behavior or price sensitivity.

```{r}
#Testing if Moderator 2 is significant
anova(cash_model, cash_model_moderation)
lrtest(cash_model, cash_model_moderation)
```

Both the ANOVA and LRT yield non-significant p-values. This suggests that the inclusion of the payment method interaction does not provide a better fit than the simple additive model. Thus, H2 is not supported.

```{r}
#2.3 Moderated Model 3
estb_model = lm(Qty_Dev ~ price_c + estb, data = detailed_data_perep_estb)
estb_model_moderation = lm(Qty_Dev ~ price_c * estb, data = detailed_data_perep_estb)
summary(estb_model)
summary(estb_model_moderation)
```

The analysis of establishment types yields comparable results. None of the coefficients for price, establishment type, or their interaction terms achieve statistical significance. The low $R^2$ values suggest that these variables do not effectively predict deviations in purchase quantity.

```{r}
#Testing if Moderator 3 is significant
anova(estb_model, estb_model_moderation)
lrtest(estb_model, estb_model_moderation)
```

The model comparison tests (ANOVA and LRT) evaluate the collective contribution of the interaction terms associated with the `estb` factor. The results are non-significant, indicating that the relationship between price and demand does not vary significantly across the different establishment types. Therefore, H3 is not supported.
